Model Architecture Design,
	I followed Nvidia's paper provided by the course, and did not explore many different network architecture. However I multiplied the depth of Conv2D layers and number of nuerons in Dense layers. The intuition is that, comparing with real-world data in Nvidia's paper, the picture/steering generated from the simulator have variance, so a increased power of CNN is needed.
	
	
Architecture Characteristics,
	The architecture is featured by 4 Conv2D layers in a row then followed by 4 Dense layers in a row.
	The 4 Conv2D layers are with increasingly greater depth, the shallower ones are mean to catch the common features shared by different patterns and structures. The final layer are deepest one as it can represent more complex structures composed by features generated in previous layer.
	On the other hand, the complexity of dense layers are in a descending order. Because the ones that just followed Conv2D layer are meant to resolve most complex interactions among features and gradually towards a sigle value regression problem.
	 No pooling or dropout layers were used. Empirically, I did not find them helpful in obtaining a working model more easily, I think the project itself is try to 'overfitting' the track. Since we are training and testing the model on the same track.


Data Preprocessing and Model Training
	- Each picture feed to the network was normalized to [-0.5, 0.5] range
	- I obtained a working model by the following training process:
		1. Get a basic model, i.e. the car can drive by itself but may fail on sharp bends
		2. Using the basic model plus a semi-automate program to record higher quality data;
		3. Train the model got in the 1st step with newly generated data to get the final model.
		
	The details of each step are described below:
		1. In order to get a basic model described above, I limited the max steering angle to +/- 0.17, reasoning that the unnecessary steering caused by human 'driver' in straight roads will greatly affect the 'stability' of the self-driving.
	
		2. using this basic model plus a semi-automate drive.py to record high quality data:
			A. the semi-automate drive.py allows the car to drive using a given model while accepting keyboard input to steer. The keyboard input will override or change the value of predicted steering angle, so I could get desired steering angle by simple key combination.  (The idea and code is based on Joe Chen's 'agile trainer' but I did several improvements and modifications to let it work with keyboard)
				a. Set the steering angle (empirically) to a proper value: 5.8 degree or 0.183
				b. implement decaying effect: after the key is released, the steering angle will return to 0 gradually in the next 5 'frame' instead of drop to 0 all of a sudden.
				c. use up/down arrow to get multiplied (1.25x) or halved steering angle to deal with sharper or 'gentler' bends
				d. notice that by just pressing the down arrow, the car will be using the halved predicted steering value, so that it further reduce the unwanted steering in straight roads and correct any over-steering in bends.

			B. The newly recorded data have the following qualities:
				a. near 0 steering on straight roads
				b. smooth and 'just right' steering angle in bends, esp. the sharp ones.
				c. record 3-4 laps of data
			
		3. Train the basic model further with newly generated data		
			- implement a generator: to generate 8 random shifted pictures, between (-100, 100) pixels and adjust steering accordingly.  0.05 / 40 (angle per pixel)
			- using the data to further train the first model (same architecture with weights gained in previous phase).
		
		
	Things that helped:
		- The idea of suppressing and smoothing of steering value in the first training phase. 
		- Udacity's Data. I was able to produced the first model that made it to the end of the bridge with it (using the method mentioned in the previous point).
		- PyGame based data recorder and the idea of customized (hard coded though :-( ) keyboard input.
		- The idea of using simple line chart to compare the prediction and actual steering (judged by the similarity of line shapes), this can:
			A. be used as a indicator to decide when to stop training (avoid overfitting), or choosing proper learning rate, etc.
			B. Can pre-validate training result visually, so that only models that seemed reasonably good go to the simulator, this saves a lot of time.
			C. Can visually distinguish between models that are 'way off' and those are 'almost there' and thus abandon the former and keep working on the latter.
		- Data augmentation: left/right shifting
			A. even with the high quality data, the further-trained model is not guaranteed to work.
			B. using image shifting to augment the data, a workable model is much more likely to be found and replicated.
		
	Things may help but not obviously:
		- Weighted sum the last 5 continous pictures (with a exponentially decreased weight). The intuition is that, the current steering value is not only affected by the current picture but also pictures that came before it. I kept the corresponding code in both model.py and drive.py, but its effect is not obvious comparing to other ways for smoothing the data.
